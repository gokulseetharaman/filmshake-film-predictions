version: "3.9"

services:
  backend:
    build: ./backend
    container_name: film-fund-backend
    environment:
      - OLLAMA_URL=http://ollama:11434
      - OLLAMA_EMBED_MODEL=nomic-embed-text
      - OLLAMA_LLM_MODEL=gemma3:12b
      - PORT=5000
    expose:
      - "5000"
    depends_on:
      - ollama
    volumes:
      - ./backend/funds_with_embeddings.json:/app/funds_with_embeddings.json:ro
      - ./backend/template.png:/app/template.png:ro
    restart: unless-stopped

  caddy:
    image: caddy:2.8
    container_name: film-fund-caddy
    depends_on:
      - backend
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - ./public:/srv/public:ro
      - caddy_data:/data
      - caddy_config:/config
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: film-fund-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    restart: unless-stopped

volumes:
  caddy_data:
  caddy_config:
  ollama_models:
